{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JY522IC/PointCloudProject/blob/main/Over_Sampling_Pointnet_classification_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyGu9HTiuAsZ"
      },
      "source": [
        "## Install the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B16w_gty11y2",
        "outputId": "a6e76766-0c12-41d0-bb8b-5d6b724e5451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: open3d in /usr/local/lib/python3.10/dist-packages (0.17.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.22.4)\n",
            "Requirement already satisfied: dash>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (2.9.3)\n",
            "Requirement already satisfied: werkzeug>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from open3d) (2.3.0)\n",
            "Requirement already satisfied: nbformat==5.7.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (5.7.0)\n",
            "Requirement already satisfied: configargparse in /usr/local/lib/python3.10/dist-packages (from open3d) (1.5.3)\n",
            "Requirement already satisfied: ipywidgets>=8.0.4 in /usr/local/lib/python3.10/dist-packages (from open3d) (8.0.6)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from open3d) (2.4.0)\n",
            "Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (9.5.0)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.5.3)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from open3d) (6.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open3d) (4.65.0)\n",
            "Requirement already satisfied: pyquaternion in /usr/local/lib/python3.10/dist-packages (from open3d) (0.9.9)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat==5.7.0->open3d) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat==5.7.0->open3d) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat==5.7.0->open3d) (5.3.0)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat==5.7.0->open3d) (5.7.1)\n",
            "Requirement already satisfied: Flask>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.2.4)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.13.1)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.0.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (5.5.6)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.7 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (4.0.7)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2022.7.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=2.2.3->open3d) (2.1.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.0.4->dash>=2.6.0->open3d) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.0.4->dash>=2.6.0->open3d) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.0.4->dash>=2.6.0->open3d) (8.1.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.4->open3d) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.4->open3d) (6.3.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.18.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.8.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat==5.7.0->open3d) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat==5.7.0->open3d) (0.19.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.16.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat==5.7.0->open3d) (3.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.6)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=8.0.4->open3d) (23.2.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: provider in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.26.82 in /usr/local/lib/python3.10/dist-packages (from provider) (1.26.137)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from provider) (8.1.3)\n",
            "Requirement already satisfied: common-fate-schema<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from provider) (0.7.0)\n",
            "Requirement already satisfied: pydantic<2.0.0,>=1.10.5 in /usr/local/lib/python3.10/dist-packages (from provider) (1.10.7)\n",
            "Requirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.10/dist-packages (from provider) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from provider) (4.5.0)\n",
            "Requirement already satisfied: botocore<1.30.0,>=1.29.137 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.26.82->provider) (1.29.137)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.26.82->provider) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.26.82->provider) (0.6.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.137->boto3<2.0.0,>=1.26.82->provider) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.137->boto3<2.0.0,>=1.26.82->provider) (1.26.15)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.137->boto3<2.0.0,>=1.26.82->provider) (1.16.0)\n",
            "2.0.1+cu118\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-cluster\n",
            "  Using cached torch_cluster-1.6.1.tar.gz (53 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.22.4)\n",
            "Building wheels for collected packages: torch-cluster\n"
          ]
        }
      ],
      "source": [
        "# install the required libraries\n",
        "!pip install open3d\n",
        "!pip install provider\n",
        "\n",
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "# !pip install -q torch-cluster -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-cluster\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# Helper functions for visualization.\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "def visualize_mesh(pos, face):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(projection='3d')\n",
        "    # ax = fig.gca(projection='3d')\n",
        "    ax.axes.xaxis.set_ticklabels([])\n",
        "    ax.axes.yaxis.set_ticklabels([])\n",
        "    ax.axes.zaxis.set_ticklabels([])\n",
        "    ax.plot_trisurf(pos[:, 0], pos[:, 1], pos[:, 2], triangles=data.face.t(), antialiased=False)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_points(pos, edge_index=None, index=None):\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    if edge_index is not None:\n",
        "        for (src, dst) in edge_index.t().tolist():\n",
        "             src = pos[src].tolist()\n",
        "             dst = pos[dst].tolist()\n",
        "             plt.plot([src[0], dst[0]], [src[1], dst[1]], linewidth=1, color='black')\n",
        "    if index is None:\n",
        "        plt.scatter(pos[:, 0], pos[:, 1], s=50, zorder=1000)\n",
        "    else:\n",
        "       mask = torch.zeros(pos.size(0), dtype=torch.bool)\n",
        "       mask[index] = True\n",
        "       plt.scatter(pos[~mask, 0], pos[~mask, 1], s=50, color='lightgray', zorder=1000)\n",
        "       plt.scatter(pos[mask, 0], pos[mask, 1], s=50, zorder=1000)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLsfKiAIuG2o"
      },
      "source": [
        "# Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4ZS3BZD185E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "16e179b4-e6fe-4c7a-bb24-ae8997101ca5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a75ce3d70521>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInMemoryDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_zip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_networkx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# numpy compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_numpy_dev\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_is_numpy_dev\u001b[0m  \u001b[0;31m# pyright: ignore # noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from pandas.compat.numpy import (\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mis_numpy_dev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mnp_version_under1p21\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/compat/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# numpy versioning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m from pandas.core.util.hashing import (  # noqa:F401\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mhash_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mhash_pandas_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/util/hashing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m from pandas.core.dtypes.common import (\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mis_list_like\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(data, name, bytecode_path, source_path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "from torch_geometric.data import InMemoryDataset, Data, download_url, extract_zip\n",
        "from torch_geometric.utils.convert import to_networkx\n",
        "import networkx as nx\n",
        "from tqdm import tqdm\n",
        "import open3d as o3d\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90lmrzPKulba"
      },
      "source": [
        "# The function to load the data and return positions in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8w5Xam31_Zk"
      },
      "outputs": [],
      "source": [
        "# input the file path and return the data of all labels\n",
        "def loadData(path):\n",
        "    # Load the pcd file\n",
        "    pcd = o3d.io.read_point_cloud(path)\n",
        "\n",
        "    # Control the number of points in the point cloud file\n",
        "    downpcd_farthest = pcd.farthest_point_down_sample(5000)\n",
        "\n",
        "    point_xyz = np.asarray(downpcd_farthest.points)\n",
        "\n",
        "    return point_xyz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vItA3tXB9Xsg"
      },
      "source": [
        "# Do the point cloud normilization to make the point cloud to be around the center point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tekyx7i2OtxS"
      },
      "outputs": [],
      "source": [
        "def pc_normalize(pc):\n",
        "    \"\"\"\n",
        "    Point data normilization\n",
        "    :param pc: the pc to normilized\n",
        "    :return: the point data after normilization\n",
        "    \"\"\"\n",
        "    # the average value\n",
        "    centroid = np.mean(pc, axis=0)\n",
        "    pc = pc - centroid\n",
        "    m = np.max(np.sqrt(np.sum(pc ** 2, axis=1)))\n",
        "    # rescale\n",
        "    pc = pc / m\n",
        "    return pc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KHEoNd8-PEi"
      },
      "source": [
        "# Define the dataset using Pytorch Geometry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEYkX0p_2C0L"
      },
      "outputs": [],
      "source": [
        "class Operating_room_classification(InMemoryDataset):\n",
        "\n",
        "    # Base url to download the files\n",
        "    # url = 'http://nrvis.com/download/data/labeled/FRANKENSTEIN.zip'\n",
        "\n",
        "    def __init__(self, root, transform=None, pre_transform=None):\n",
        "        super(Operating_room_classification, self).__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        # List of the raw files\n",
        "        return []\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        # return list of files should be in processed dir, if found - skip processing\n",
        "        return ['data.pt']\n",
        "\n",
        "    # def download(self):\n",
        "    #     # Download the file specified in self.url and store\n",
        "    #     # it in self.raw_dir\n",
        "    #     path = download_url(self.url, self.raw_dir)\n",
        "    #     extract_zip(path, self.raw_dir)\n",
        "    #     # The zip file is removed\n",
        "    #     os.unlink(path)\n",
        "\n",
        "\n",
        "    def process(self):\n",
        "\n",
        "      if State == 1:\n",
        "        df = train_index\n",
        "      else:\n",
        "        df = test_index\n",
        "\n",
        "      # In the loop we extract the nodes' embeddings, edges connectivity for\n",
        "      # and label for a graph, process the information and put it in a Data\n",
        "      # object, then we add the object to a list\n",
        "      data_list = []\n",
        "      root_new = '/content/drive/MyDrive/Colab Notebooks/Pointnet 0428/Down20000 4'\n",
        "\n",
        "      for index, row in df.iterrows():\n",
        "\n",
        "        # load the data\n",
        "        point_pos = loadData(os.path.join(root_new, row[1]))\n",
        "\n",
        "        # Normilize the data\n",
        "        new_points = pc_normalize(point_pos)\n",
        "\n",
        "        # Calculate the normal information\n",
        "        device = o3d.core.Device(\"CPU:0\")\n",
        "        dtype = o3d.core.float64\n",
        "        pcd = o3d.t.geometry.PointCloud(device)\n",
        "        pcd.point.positions = o3d.core.Tensor(new_points, dtype, device)\n",
        "        pcd = pcd.to_legacy()\n",
        "        radius = 0.01  # Searching Radius\n",
        "        max_nn = 30  # Number of neighboring points to estimate normal vector\n",
        "        pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius, max_nn))\n",
        "\n",
        "        # Convert the position and label information into the Pytorch format\n",
        "        Pos = torch.tensor(new_points,dtype=torch.float32)\n",
        "        Y = torch.tensor(row[2],dtype=torch.long)\n",
        "        Normals = torch.tensor(np.asarray(pcd.normals),dtype=torch.float32)\n",
        "\n",
        "        # Save the data\n",
        "        graph = Data(pos = Pos, y = Y, normal = Normals)\n",
        "        data_list.append(graph)\n",
        "\n",
        "        print(index)\n",
        "\n",
        "      # Apply the functions specified in pre_filter and pre_transform\n",
        "      if self.pre_filter is not None:\n",
        "          data_list = [data for data in data_list if self.pre_filter(data)]\n",
        "\n",
        "      if self.pre_transform is not None:\n",
        "          data_list = [self.pre_transform(data) for data in data_list]\n",
        "\n",
        "      # Store the processed data\n",
        "      data, slices = self.collate(data_list)\n",
        "      torch.save((data, slices), self.processed_paths[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeQ5xFA-_Wti"
      },
      "source": [
        "# Create the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gytBZg5o2F9J"
      },
      "outputs": [],
      "source": [
        "import torch_geometric.transforms as T\n",
        "\n",
        "# load data\n",
        "df = pd.read_csv(r'/content/drive/MyDrive/Colab Notebooks/Pointnet 0428/Two Class Down20000 4 with label.csv')\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "train_index=df.sample(frac=0.7)\n",
        "test_index=df[~df.index.isin(train_index.index)]\n",
        "\n",
        "# Create the train and test dataset based on the direction\n",
        "State = 1\n",
        "trainDataset = Operating_room_classification(root='/content/drive/MyDrive/Colab Notebooks/Pointnet 0428/Down20000 4/SittingPreparingOperating/Train')\n",
        "State = 2\n",
        "testDataset = Operating_room_classification(root='/content/drive/MyDrive/Colab Notebooks/Pointnet 0428/Down20000 4/SittingPreparingOperating/Test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT5UesWKaiVa"
      },
      "source": [
        "# Rescale the point to its center position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFkbIPpYDs-k"
      },
      "outputs": [],
      "source": [
        "import open3d.core as o3c\n",
        "\n",
        "# Load the point cloud data\n",
        "data_1 = o3d.io.read_point_cloud('/content/drive/MyDrive/Colab Notebooks/Pointnet 0428/Down20000 4/1380.ply')\n",
        "\n",
        "# Visualize the point cloud\n",
        "o3d.visualization.draw_plotly([data_1])\n",
        "\n",
        "# Normalize the point cloud data\n",
        "new_points = pc_normalize(np.asarray(data_1.points))\n",
        "\n",
        "# print(new_points)\n",
        "\n",
        "# Define the open3d format and visualize the data\n",
        "device = o3d.core.Device(\"CPU:0\")\n",
        "dtype = o3d.core.float64\n",
        "\n",
        "# Create an empty point cloud\n",
        "# Use pcd.point to access the points' attributes,\n",
        "pcd = o3d.t.geometry.PointCloud(device)\n",
        "# pcd = o3d.t.geometry.PointCloud()\n",
        "\n",
        "# Default attribute: \"positions\".\n",
        "# This attribute is created by default and is required by all point clouds.\n",
        "# The shape must be (N, 3). The device of \"positions\" determines the device\n",
        "# of the point cloud.\n",
        "pcd.point.positions = o3d.core.Tensor(new_points, dtype, device)\n",
        "pcd.point.normals = o3d.core.Tensor(np.asarray(data_1.normals), dtype, device)\n",
        "pcd.point.colors = o3d.core.Tensor(np.asarray(data_1.colors), dtype, device)\n",
        "pcd = pcd.to_legacy()\n",
        "o3d.visualization.draw_plotly([pcd])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsoeIaTBDLEn"
      },
      "source": [
        "## Define the Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFVYUFmDEsgb"
      },
      "source": [
        "Pointnet Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgCZ5jQiHcVN"
      },
      "outputs": [],
      "source": [
        "# Pointnet layer\n",
        "from torch.nn import Sequential, Linear, ReLU\n",
        "from torch_geometric.nn import MessagePassing\n",
        "\n",
        "\n",
        "class PointNetLayer(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        # Message passing with \"max\" aggregation.\n",
        "        super().__init__(aggr='max')\n",
        "\n",
        "        # Initialization of the MLP:\n",
        "        # Here, the number of input features correspond to the hidden node\n",
        "        # dimensionality plus point dimensionality (=3).\n",
        "        self.mlp = Sequential(Linear(in_channels+3, out_channels),\n",
        "                              ReLU(),\n",
        "                              Linear(out_channels, out_channels))\n",
        "\n",
        "    def forward(self, h, pos, edge_index):\n",
        "        # Start propagating messages.\n",
        "        return self.propagate(edge_index, h=h, pos=pos)\n",
        "\n",
        "    def message(self, h_j, pos_j, pos_i):\n",
        "        # h_j defines the features of neighboring nodes as shape [num_edges, in_channels]\n",
        "        # pos_j defines the position of neighboring nodes as shape [num_edges, 3]\n",
        "        # pos_i defines the position of central nodes as shape [num_edges, 3]\n",
        "\n",
        "        # Compute spatial relation.\n",
        "        input = pos_j - pos_i\n",
        "\n",
        "        input = input.to(torch.float32)\n",
        "\n",
        "        if h_j is not None:\n",
        "            # In the first layer, we may not have any hidden node features,\n",
        "            # so we only combine them in case they are present.\n",
        "            input = torch.cat([h_j, input], dim=-1)\n",
        "\n",
        "        return self.mlp(input)  # Apply our final MLP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBzasuHKHVMU"
      },
      "source": [
        "Main network structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSr7vx7eJmI6"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn.conv import edge_conv\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_cluster import knn_graph\n",
        "from torch_geometric.nn import global_max_pool\n",
        "\n",
        "class PointNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = PointNetLayer(3, 32)\n",
        "        self.conv2 = PointNetLayer(32, 32)\n",
        "        self.classifier = Linear(32, trainDataset.num_classes)\n",
        "\n",
        "    def forward(self, pos, batch):\n",
        "        # Compute the kNN graph:\n",
        "        # Here, we need to pass the batch vector to the function call in order\n",
        "        # to prevent creating edges between points of different examples.\n",
        "        # We also add `loop=True` which will add self-loops to the graph in\n",
        "        # order to preserve central point information.\n",
        "        edge_index = knn_graph(pos, k=16, batch=batch, loop=True)\n",
        "        # print(edge_index)\n",
        "        # print(edge_index.shape)\n",
        "        # print(edge_index.type)\n",
        "\n",
        "        # Start bipartite message passing.\n",
        "        h = self.conv1(h=pos, pos=pos, edge_index=edge_index)\n",
        "\n",
        "        h = h.relu()\n",
        "\n",
        "        h = self.conv2(h=h, pos=pos, edge_index=edge_index)\n",
        "\n",
        "        h = h.relu()\n",
        "\n",
        "        # Global Pooling.\n",
        "        h = global_max_pool(h, batch)  # [num_examples, hidden_channels]\n",
        "\n",
        "        # Classifier.\n",
        "        return self.classifier(h)\n",
        "\n",
        "# Show the network structure\n",
        "model = PointNet()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85UAXmpWHpmC"
      },
      "source": [
        "Train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKPI5sHkJoUd"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Javascript  # Restrict height of output cell.\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "from torch_geometric.loader import DataLoader\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "import datetime\n",
        "import logging\n",
        "import provider\n",
        "import importlib\n",
        "import shutil\n",
        "import argparse\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from IPython.display import Javascript  # Restrict height of output cell.\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "\n",
        "# train_dataset = GeometricShapes(root='data/GeometricShapes', train=True,\n",
        "#                                 transform=SamplePoints(128))\n",
        "# test_dataset = GeometricShapes(root='data/GeometricShapes', train=False,\n",
        "#                                transform=SamplePoints(128))\n",
        "\n",
        "# Over Sampling the data\n",
        "y_label = np.asarray(trainDataset.data.y)\n",
        "y_weight = compute_sample_weight(class_weight = 'balanced', y = y_label)\n",
        "Sampler = WeightedRandomSampler(y_weight, len(y_label), replacement=True)\n",
        "\n",
        "# Load the data\n",
        "trainDataLoader = DataLoader(trainDataset, batch_size=20, sampler = Sampler)\n",
        "testDataLoader = DataLoader(testDataset, batch_size=10)\n",
        "\n",
        "# Load the Pointnet\n",
        "model = PointNet()\n",
        "# Define the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "# Define loss criterion.\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the log\n",
        "def log_string(str):\n",
        "  logger.info(str)\n",
        "  print(str)\n",
        "\n",
        "\n",
        "# log_dir = '/content/drive/MyDrive/Colab Notebooks/Pointnet 0428/LogsCoordinateCalibPointnetPlusGnn/classification/2023-05-15_15-47'\n",
        "log_dir = None\n",
        "model_name = 'PointNetPlusGNNWithoutCoordinateCalibration'\n",
        "\n",
        "'''HYPER PARAMETER'''\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "\n",
        "'''CREATE DIR'''\n",
        "timestr = str(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M'))\n",
        "exp_dir = Path('/content/drive/MyDrive/Colab Notebooks/Pointnet 0428/ResultSittingPreparingOperating/LogsPointnetAndGNN')\n",
        "exp_dir.mkdir(exist_ok=True)\n",
        "exp_dir = exp_dir.joinpath('classification')\n",
        "exp_dir.mkdir(exist_ok=True)\n",
        "\n",
        "if log_dir is None:\n",
        "    exp_dir = exp_dir.joinpath(timestr)\n",
        "else:\n",
        "    exp_dir = exp_dir.joinpath(log_dir)\n",
        "\n",
        "exp_dir.mkdir(exist_ok=True)\n",
        "checkpoints_dir = exp_dir.joinpath('checkpoints/')\n",
        "checkpoints_dir.mkdir(exist_ok=True)\n",
        "log_dir = exp_dir.joinpath('logs/')\n",
        "log_dir.mkdir(exist_ok=True)\n",
        "\n",
        "'''LOG'''\n",
        "logger = logging.getLogger(\"Model\")\n",
        "logger.setLevel(logging.INFO)\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "file_handler = logging.FileHandler('%s/%s.log' % (log_dir, model_name))\n",
        "file_handler.setLevel(logging.INFO)\n",
        "file_handler.setFormatter(formatter)\n",
        "logger.addHandler(file_handler)\n",
        "log_string('PARAMETER ...')\n",
        "\n",
        "try:\n",
        "    checkpoint = torch.load(str(exp_dir) + '/checkpoints/best_model.pth')\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    log_string('Use pretrain model')\n",
        "except:\n",
        "    log_string('No existing model, starting training from scratch...')\n",
        "    start_epoch = 0\n",
        "\n",
        "\n",
        "# Define the train function\n",
        "def train(model, optimizer, loader):\n",
        "\n",
        "  # Train model\n",
        "  model.train()\n",
        "\n",
        "  total_loss = 0\n",
        "  # itar = 0\n",
        "\n",
        "  for data in tqdm(loader,desc='Processing'):\n",
        "    # itar+= 1\n",
        "    # print(itar)\n",
        "\n",
        "    # Clear gradients.\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # data.pos = data.pos.to(torch.float32)\n",
        "    # print(data.pos.shape)\n",
        "    # print(data.batch.shape)\n",
        "\n",
        "    # Forward pass.\n",
        "    logits = model(data.pos, data.batch)\n",
        "\n",
        "    # Loss computation.\n",
        "    loss = criterion(logits, data.y)\n",
        "\n",
        "    # Backward pass.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update model parameters.\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item() * data.num_graphs\n",
        "    # print(total_loss)\n",
        "\n",
        "  return total_loss / len(train_loader.dataset)\n",
        "\n",
        "# Define the test function\n",
        "@torch.no_grad()\n",
        "def test(model, loader):\n",
        "\n",
        "  # Define the eval\n",
        "  model.eval()\n",
        "\n",
        "  total_correct = 0\n",
        "  for data in loader:\n",
        "    data.pos = data.pos.to(torch.float32)\n",
        "    logits = model(data.pos, data.batch)\n",
        "    pred = logits.argmax(dim=-1)\n",
        "    total_correct += int((pred == data.y).sum())\n",
        "\n",
        "  return total_correct / len(loader.dataset)\n",
        "\n",
        "best_instance_acc = 0.0\n",
        "\n",
        "# Define the main part\n",
        "'''TRANING'''\n",
        "logger.info('Start training...')\n",
        "for epoch in range(1, 20):\n",
        "    loss = train(model, optimizer, train_loader)\n",
        "    test_acc = test(model, test_loader)\n",
        "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "    if (test_acc >= best_instance_acc):\n",
        "      best_instance_acc = test_acc\n",
        "      best_epoch = epoch + 1\n",
        "\n",
        "    # if (class_acc >= best_class_acc):\n",
        "    #     best_class_acc = class_acc\n",
        "    log_string('Test Instance Accuracy: %f' % (test_acc))\n",
        "    log_string('Best Instance Accuracy: %f' % (best_instance_acc))\n",
        "\n",
        "    if (test_acc >= best_instance_acc):\n",
        "      logger.info('Save model...')\n",
        "      savepath = str(checkpoints_dir) + '/best_model.pth'\n",
        "      log_string('Saving at %s' % savepath)\n",
        "      state = {\n",
        "          'epoch': best_epoch,\n",
        "          'instance_acc': test_acc,\n",
        "          'model_state_dict': model.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "      }\n",
        "      torch.save(state, savepath)\n",
        "\n",
        "logger.info('End of training...')\n",
        "\n",
        "# Save the model\n",
        "# PATH = '/content/drive/MyDrive/Colab Notebooks/Pointnet 0428/CoordinateCalibratePointnetPlusModel0504.pt'\n",
        "# torch.save(model, PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_0CP0cKyv7J"
      },
      "outputs": [],
      "source": [
        "# Test the model saved\n",
        "model_new = torch.load('/content/drive/MyDrive/Colab Notebooks/Pointnet 0428/CoordinateCalibratePointnetPlusModel0504.pt')\n",
        "point_pos = loadData('/content/drive/MyDrive/Colab Notebooks/Pointnet 0428/Down20000 4/77250.ply')\n",
        "new_points = pc_normalize(point_pos)\n",
        "device = o3d.core.Device(\"CPU:0\")\n",
        "dtype = o3d.core.float64\n",
        "\n",
        "# # Create an empty point cloud\n",
        "# # Use pcd.point to access the points' attributes\n",
        "pcd = o3d.t.geometry.PointCloud(device)\n",
        "# pcd = o3d.t.geometry.PointCloud()\n",
        "\n",
        "# Default attribute: \"positions\".\n",
        "# This attribute is created by default and is required by all point clouds.\n",
        "# The shape must be (N, 3). The device of \"positions\" determines the device\n",
        "# of the point cloud.\n",
        "pcd.point.positions = o3d.core.Tensor(new_points, dtype, device)\n",
        "pcd = pcd.to_legacy()\n",
        "o3d.visualization.draw_plotly([pcd])\n",
        "\n",
        "test_points = torch.tensor(new_points,dtype=torch.float32)\n",
        "\n",
        "logits = model_new(test_points,None)\n",
        "pred = np.asarray(logits.argmax(dim=-1))\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kp-TrakyLLoL"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger('test')\n",
        "logger.setLevel(level=logging.DEBUG)\n",
        "\n",
        "formatter = logging.Formatter('%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s')\n",
        "\n",
        "file_handler = logging.FileHandler('/content/drive/MyDrive/Colab Notebooks/Pointnet 0428/LogsCoordinateCalibPointnetPlusGnn/test2.log')\n",
        "file_handler.setLevel(level=logging.INFO)\n",
        "file_handler.setFormatter(formatter)\n",
        "\n",
        "stream_handler = logging.StreamHandler()\n",
        "stream_handler.setLevel(logging.DEBUG)\n",
        "stream_handler.setFormatter(formatter)\n",
        "\n",
        "logger.addHandler(file_handler)\n",
        "logger.addHandler(stream_handler)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1ir1ZmF9UpsArONsXwoyzzEhTqb9ah6W2",
      "authorship_tag": "ABX9TyPvq+KyqX63EmiJpWRfyxny",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}